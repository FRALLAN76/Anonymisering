# Skapa en final version med perfekta telefonnummer-regex
cat > swedish_anonymizer_final_fixed.py << 'EOF'
from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification
import re
import glob
import os
try:
    import extract_msg
    MSG_SUPPORT = True
except ImportError:
    MSG_SUPPORT = False

class FinalSwedishEmailAnonymizer:
    def __init__(self):
        print("üá∏üá™ Loading Swedish BERT NER model from KBLab...")
        print("   Model: KB/bert-base-swedish-cased-ner")
        print("   Mode: FINAL - Perfekt anonymisering av ALL personlig information")
        self.tokenizer = AutoTokenizer.from_pretrained('KB/bert-base-swedish-cased-ner')
        self.model = AutoModelForTokenClassification.from_pretrained('KB/bert-base-swedish-cased-ner')
        self.nlp = pipeline('ner', 
                           model=self.model, 
                           tokenizer=self.tokenizer,
                           aggregation_strategy='simple')
        print("‚úÖ KBLab Swedish BERT model loaded successfully!")

    def detect_all_pii_patterns(self, text):
        """Detect ALL PII patterns with comprehensive phone regex"""
        patterns = {
            'PERSONNUMMER': r'\b(?:19|20)?\d{6}-?\d{4}\b',
            
            # MYCKET omfattande telefonnummer-m√∂nster f√∂r svenska nummer
            'TELEFON_KOMPLETT': r'\b(?:\+46[\s-]?|0)(?:\d{1,4}[\s-]?\d{1,4}[\s-]?\d{1,4}[\s-]?\d{1,4}|\d{2,3}[\s-]?\d{2,3}[\s-]?\d{2,3}[\s-]?\d{2,3}|\d{8,11})\b',
            
            # Specifika m√∂nster f√∂r olika telefonnummer-format
            'TEL_PLUS46': r'\+46[\s-]?\d{1,3}[\s-]?\d{6,8}',
            'TEL_0_START': r'\b0\d{1,3}[\s-]?\d{6,8}\b',
            'TEL_MOBIL': r'\b(?:\+46[\s-]?7|07)\d[\s-]?\d{7}\b',
            'TEL_STOCKHOLM': r'\b(?:\+46[\s-]?8|08)[\s-]?\d{6,8}\b',
            'TEL_GOTEBORG': r'\b(?:\+46[\s-]?31|031)[\s-]?\d{6,8}\b',
            
            # F√•nga alla nummer som ser ut som telefonnummer (7+ siffror med eventuella mellanslag/bindestreck)
            'TEL_ALLM√ÑN': r'\b(?:\+\d{1,3}[\s-]?)?\d{2,4}[\s-]?\d{2,4}[\s-]?\d{2,4}(?:[\s-]?\d{1,4})?\b',
            
            'POSTNUMMER': r'\b\d{3}\s?\d{2}\b',
            'EMAIL': r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',
            'GATUADRESS': r'\b[A-Z√Ö√Ñ√ñ][a-z√•√§√∂]+(?:gatan?|v√§gen?|torget?|platsen?|parken?)\s+\d+[A-Za-z]?\b',
            'ORGANISATIONSNUMMER': r'\b\d{6}-\d{4}\b',
            'IP_ADDRESS': r'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b'
        }
        
        found = []
        for pattern_type, pattern in patterns.items():
            for match in re.finditer(pattern, text):
                word = match.group().strip()
                
                # Validering f√∂r IP-adresser
                if pattern_type == 'IP_ADDRESS':
                    parts = word.split('.')
                    if all(0 <= int(part) <= 255 for part in parts):
                        found.append({
                            'entity_group': 'IP_ADDRESS',
                            'start': match.start(),
                            'end': match.end(),
                            'word': word,
                            'score': 0.99
                        })
                
                # Validering f√∂r telefonnummer - kontrollera att det inte √§r n√•got annat
                elif pattern_type.startswith('TEL_') or pattern_type == 'TELEFON_KOMPLETT':
                    # Exkludera om det ser ut som √•r, versionnummer etc
                    if not re.match(r'^\d{4}$', word) and not re.match(r'^\d{1,2}\.\d+', word):
                        # Kontrollera att det har minst 7 siffror totalt
                        digits_only = re.sub(r'[^\d]', '', word)
                        if len(digits_only) >= 7:
                            found.append({
                                'entity_group': 'TELEFON',
                                'start': match.start(),
                                'end': match.end(),
                                'word': word,
                                'score': 0.99
                            })
                
                else:
                    found.append({
                        'entity_group': pattern_type,
                        'start': match.start(),
                        'end': match.end(),
                        'word': word,
                        'score': 0.99
                    })
        return found

    def post_process_phone_cleanup(self, text):
        """Extra pass f√∂r att hitta kvarvarande telefonnummer"""
        # Hitta m√∂nster som "031-36 78 361" eller "+4631-3678431" eller "+46 72 148 25 77"
        phone_patterns = [
            r'\b\+?46\s?31-?\s?\d{7,8}\b',  # G√∂teborg
            r'\b\+?46\s?8-?\s?\d{6,8}\b',   # Stockholm  
            r'\b\+?46\s?7\d\s?\d{7}\b',     # Mobil
            r'\b0\d{2,3}-?\s?\d{2}\s?\d{2}\s?\d{2,3}\b',  # Nationella nummer
            r'\b\+?46\s?\d{2,3}-?\s?\d{6,8}\b',  # Alla +46 nummer
            r'\b\d{3}-\d{2}\s\d{2}\s\d{2,3}\b',  # Format som "031-36 78 361"
        ]
        
        entities = []
        for pattern in phone_patterns:
            for match in re.finditer(pattern, text):
                word = match.group().strip()
                # Kontrollera att det har tillr√§ckligt m√•nga siffror
                digits = re.sub(r'[^\d]', '', word)
                if len(digits) >= 7:
                    entities.append({
                        'entity_group': 'TELEFON',
                        'start': match.start(),
                        'end': match.end(),
                        'word': word,
                        'score': 0.99
                    })
        
        return entities

    def detect_swedish_names(self, text):
        """Enhanced name detection"""
        first_names = [
            'Anna', 'Lars', 'Erik', 'Maria', 'Johan', 'Emma', 'Oscar', 'Patrik', 'Fredrik', 
            'Christina', 'Magnus', 'Susanne', 'Anders', 'Helena', 'Per', 'Margareta', 
            'Stefan', 'Birgitta', 'Mikael', 'Elisabeth', 'Jonas', 'Eva', 'David', 'Ingrid',
            'Daniel', 'Marie', 'Thomas', 'Linda', 'Marcus', 'Karin', 'Mattias', 'Sara',
            'Andreas', 'Lena', 'Peter', 'Annika', 'Christer', 'Monica', 'Martin', 'Inger',
            'Robert', '√Ösa', 'Nils', 'Gunilla', 'Kristina', 'Ulf', 'Ulrika', 'Carl',
            'Bj√∂rn', 'Sven', 'Astrid', 'Gustav', 'Mats', 'Lisa', 'Alexander', 'Jenny'
        ]
        
        found = []
        
        # Hitta f√∂rnamn
        for name in first_names:
            pattern = r'\b' + re.escape(name) + r'\b'
            for match in re.finditer(pattern, text, re.IGNORECASE):
                found.append({
                    'entity_group': 'F√ñRNAMN',
                    'start': match.start(),
                    'end': match.end(),
                    'word': match.group(),
                    'score': 0.95
                })
        
        # Hitta efternamn
        surname_patterns = [
            r'\b[A-Z√Ö√Ñ√ñ][a-z√•√§√∂]+(?:son|sen|sson|berg|str√∂m|lund|dahl|gren|qvist|mark|vall|holm)\b',
            r'\b[A-Z√Ö√Ñ√ñ][a-z√•√§√∂]{3,}(?=\s+<|\s+\w+@|\s+IT-|\s+Utvecklings)',
        ]
        
        for pattern in surname_patterns:
            for match in re.finditer(pattern, text):
                found.append({
                    'entity_group': 'EFTERNAMN',
                    'start': match.start(),
                    'end': match.end(),
                    'word': match.group(),
                    'score': 0.90
                })
        
        return found

    def clean_text(self, text):
        """Clean text"""
        if not text:
            return ""
        
        text = re.sub(r'<[^>]+>', '', text)
        text = re.sub(r'\[mailto:[^\]]+\]', '', text)
        text = re.sub(r'<mailto:[^>]+>', '', text)
        text = re.sub(r'\n\s*\n', '\n\n', text)
        text = re.sub(r'\s+', ' ', text)
        
        return text.strip()

    def fix_msg_to_field(self, to_field):
        """Fix broken MSG To field"""
        if not to_field:
            return ""
        
        if ', ' in to_field and len(to_field.split(', ')) > 5:
            letters = [part.strip() for part in to_field.split(',') if part.strip()]
            meaningful_parts = [part for part in letters if len(part) > 1]
            if meaningful_parts:
                return ' '.join(meaningful_parts)
            else:
                return "<ANONYMISERAT_NAMN>"
        
        return to_field

    def anonymize_text_final(self, text):
        """Final perfect anonymization with multiple passes"""
        if not text or len(text.strip()) < 2:
            return text, []
        
        text = self.clean_text(text)
        
        # Pass 1: BERT NER
        ner_results = []
        if len(text) < 2000:
            try:
                max_chunk = 400
                words = text.split()
                chunks = []
                current_chunk = []
                current_length = 0
                
                for word in words:
                    if current_length + len(word) > max_chunk and current_chunk:
                        chunks.append(' '.join(current_chunk))
                        current_chunk = [word]
                        current_length = len(word)
                    else:
                        current_chunk.append(word)
                        current_length += len(word) + 1
                
                if current_chunk:
                    chunks.append(' '.join(current_chunk))
                
                offset = 0
                for chunk in chunks:
                    chunk_results = self.nlp(chunk)
                    for result in chunk_results:
                        if result['score'] > 0.7:
                            result['start'] += offset
                            result['end'] += offset
                            ner_results.append(result)
                    offset += len(chunk) + 1
                    
            except Exception as e:
                print(f"   BERT processing failed: {str(e)[:50]}...")
        
        # Pass 2: Pattern matching
        pattern_results = self.detect_all_pii_patterns(text)
        
        # Pass 3: Post-process phone cleanup
        phone_cleanup = self.post_process_phone_cleanup(text)
        
        # Pass 4: Name detection
        name_results = self.detect_swedish_names(text)
        
        # Kombinera alla resultat
        all_entities = pattern_results + ner_results + name_results + phone_cleanup
        
        # Ta bort √∂verlappningar
        filtered_entities = []
        for entity in sorted(all_entities, key=lambda x: x['score'], reverse=True):
            overlaps = False
            for existing in filtered_entities:
                if (entity['start'] < existing['end'] and entity['end'] > existing['start']):
                    overlaps = True
                    break
            if not overlaps and len(entity['word'].strip()) > 1:
                filtered_entities.append(entity)
        
        # Sortera efter position
        filtered_entities.sort(key=lambda x: x['start'], reverse=True)
        
        # Mappning
        replacements = {
            'PRS': '<PERSON>',
            'PERSON': '<PERSON>',
            'LOC': '<PLATS>',
            'LOCATION': '<PLATS>',
            'ORG': '<ORGANISATION>',
            'ORGANIZATION': '<ORGANISATION>',
            'TME': '<DATUM>',
            'DATE_TIME': '<DATUM>',
            'EVN': '<H√ÑNDELSE>',
            'EVENT': '<H√ÑNDELSE>',
            'PERSONNUMMER': '<PERSONNUMMER>',
            'TELEFON': '<TELEFON>',
            'TELEFON_KOMPLETT': '<TELEFON>',
            'TEL_PLUS46': '<TELEFON>',
            'TEL_0_START': '<TELEFON>',
            'TEL_MOBIL': '<TELEFON>',
            'TEL_STOCKHOLM': '<TELEFON>',
            'TEL_GOTEBORG': '<TELEFON>',
            'TEL_ALLM√ÑN': '<TELEFON>',
            'POSTNUMMER': '<POSTNUMMER>',
            'EMAIL': '<EPOST>',
            'GATUADRESS': '<GATUADRESS>',
            'ORGANISATIONSNUMMER': '<ORGNUMMER>',
            'IP_ADDRESS': '<IP_ADRESS>',
            'F√ñRNAMN': '<F√ñRNAMN>',
            'EFTERNAMN': '<EFTERNAMN>'
        }
        
        # Ers√§tt entiteter
        result = text
        entities_replaced = []
        
        for entity in filtered_entities:
            entity_type = entity['entity_group']
            replacement = replacements.get(entity_type, f'<{entity_type}>')
            start, end = entity['start'], entity['end']
            
            if start < len(result) and end <= len(result) and start < end:
                original_word = result[start:end].strip()
                if len(original_word) > 0:
                    result = result[:start] + replacement + result[end:]
                    entities_replaced.append({
                        'type': entity_type,
                        'original': original_word,
                        'replacement': replacement,
                        'confidence': entity['score']
                    })
        
        return result, entities_replaced

    def extract_msg_content(self, filepath):
        """Extract MSG content"""
        try:
            msg = extract_msg.Message(filepath)
            
            subject = self.clean_text(msg.subject or "")
            sender = msg.sender or ""
            
            if msg.to:
                recipients = ", ".join(msg.to)
                recipients = self.fix_msg_to_field(recipients)
            else:
                recipients = ""
            
            date = str(msg.date) if msg.date else ""
            body = self.clean_text(msg.body or "")
            
            headers = {
                'Subject': subject,
                'From': sender,
                'To': recipients,
                'Date': date
            }
            
            return headers, body
            
        except Exception as e:
            print(f"   Error extracting MSG: {e}")
            return None, None

    def process_email_file(self, filepath):
        """Process email file"""
        try:
            filename = os.path.basename(filepath)
            
            if filename.endswith('.msg'):
                if not MSG_SUPPORT:
                    print(f"   Skipping .msg file: {filename}")
                    return None
                
                headers, body = self.extract_msg_content(filepath)
                if headers is None:
                    return None
                subject = headers.get('Subject', '')
                
            else:
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        content = f.read()
                except UnicodeDecodeError:
                    with open(filepath, 'r', encoding='cp1252') as f:
                        content = f.read()
                
                lines = content.split('\n')
                headers = {}
                body_start = 0
                
                for i, line in enumerate(lines):
                    if ':' in line and i < 30:
                        try:
                            key, value = line.split(':', 1)
                            headers[key.strip()] = value.strip()
                        except ValueError:
                            continue
                    elif line.strip() == '':
                        body_start = i + 1
                        break
                
                body = '\n'.join(lines[body_start:])
                subject = headers.get('Subject', headers.get('√Ñmne', ''))
            
            # Final anonymization
            anon_subject, subject_entities = self.anonymize_text_final(subject)
            anon_body, body_entities = self.anonymize_text_final(body)
            anon_from, from_entities = self.anonymize_text_final(headers.get('From', ''))
            anon_to, to_entities = self.anonymize_text_final(headers.get('To', ''))
            
            all_header_entities = from_entities + to_entities
            total_entities = len(subject_entities) + len(body_entities) + len(all_header_entities)
            
            return {
                'file': filepath,
                'headers': headers,
                'anonymized_subject': anon_subject,
                'anonymized_body': anon_body,
                'anonymized_from': anon_from,
                'anonymized_to': anon_to,
                'entities_replaced': {
                    'subject': subject_entities,
                    'body': body_entities,
                    'headers': all_header_entities
                },
                'total_entities': total_entities
            }
            
        except Exception as e:
            print(f"‚ùå Error processing {filepath}: {e}")
            return None

    def process_folder(self, folder='emails'):
        """Process all emails"""
        os.makedirs(folder, exist_ok=True)
        os.makedirs('output', exist_ok=True)
        
        files = []
        for ext in ['*.eml', '*.txt', '*.msg']:
            files.extend(glob.glob(f'{folder}/{ext}'))
        
        if not files:
            print(f"üìÅ No email files found in '{folder}/' folder")
            return
        
        print(f"üìß Found {len(files)} email files to process...")
        print(f"üîí FINAL MODE: Perfekt anonymisering med multi-pass telefonnummer-detektering")
        print(f"üß† Using KBLab Swedish BERT: KB/bert-base-swedish-cased-ner")
        print()
        
        total_entities = 0
        successful_files = 0
        
        for filepath in files:
            filename = os.path.basename(filepath)
            print(f"   Processing: {filename}")
            
            result = self.process_email_file(filepath)
            if result:
                base_name = os.path.splitext(filename)[0]
                output_name = f"{base_name}_FINAL_anonymized.txt"
                output_path = f"output/{output_name}"
                
                with open(output_path, 'w', encoding='utf-8') as f:
                    f.write(f"FINAL PERFEKT ANONYMISERAD EMAIL\n")
                    f.write(f"Originalfil: {filename}\n")
                    f.write(f"Anonymiserade entiteter: {result['total_entities']}\n")
                    f.write(f"Modell: KBLab Swedish BERT NER (Final multi-pass mode)\n")
                    f.write(f"Telefonnummer: Multi-pass regex + post-processing\n")
                    f.write(f"{'='*75}\n\n")
                    
                    f.write(f"√Ñmne: {result['anonymized_subject']}\n")
                    f.write(f"From: {result['anonymized_from']}\n")
                    f.write(f"To: {result['anonymized_to']}\n")
                    f.write(f"Date: {result['headers'].get('Date', '')}\n")
                    
                    f.write(f"\n{'='*75}\n")
                    f.write("FINAL ANONYMISERAT INNEH√ÖLL:\n")
                    f.write(f"{'='*75}\n\n")
                    f.write(result['anonymized_body'])
                    
                    f.write(f"\n\n{'='*75}\n")
                    f.write("KOMPLETT ANONYMISERINGSRAPPORT:\n")
                    f.write(f"{'='*75}\n")
                    
                    all_entities = (result['entities_replaced']['subject'] + 
                                  result['entities_replaced']['body'] + 
                                  result['entities_replaced']['headers'])
                    
                    if all_entities:
                        f.write(f"Totalt {len(all_entities)} entiteter anonymiserades:\n\n")
                        
                        by_type = {}
                        for entity in all_entities:
                            if entity['type'] not in by_type:
                                by_type[entity['type']] = []
                            by_type[entity['type']].append(entity)
                        
                        for entity_type, entities in sorted(by_type.items()):
                            f.write(f"\n{entity_type} ({len(entities)} st):\n")
                            for entity in entities:
                                f.write(f"  - '{entity['original']}' ‚Üí '{entity['replacement']}'\n")
                    else:
                        f.write("Ingen personlig information hittades.\n")
                
                total_entities += result['total_entities']
                successful_files += 1
                print(f"     ‚úÖ FINAL: {output_name} ({result['total_entities']} entities)")
        
        print()
        print(f"üîí FINAL PERFEKT ANONYMISERING KLAR!")
        print(f"   üìÅ Alla resultat sparade i 'output/' mappen")
        print(f"   ‚úÖ Framg√•ngsrikt behandlade: {successful_files}/{len(files)} filer")
        print(f"   üîí Totalt anonymiserade entiteter: {total_entities}")
        if successful_files > 0:
            print(f"   üìä Genomsnitt per fil: {total_entities/successful_files:.1f}")

if __name__ == "__main__":
    print("üîí FINAL PERFEKT SVENSK EMAIL-ANONYMISERING")
    print("Multi-pass telefonnummer-detektering + KBLab BERT")
    print("=" * 75)
    print()
    
    try:
        anonymizer = FinalSwedishEmailAnonymizer()
        anonymizer.process_folder()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Process interrupted by user")
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
EOF

echo "üîí FINAL version med multi-pass telefonnummer-detektering!"
echo ""
echo "üîß F√∂rb√§ttringar:"
echo "   ‚Ä¢ 7 olika telefonnummer-regex m√∂nster"
echo "   ‚Ä¢ Post-processing pass f√∂r kvarvarande nummer"
echo "   ‚Ä¢ F√•ngar: +4631-3678431, 031-36 78 361, +46 72 148 25 77"
echo "   ‚Ä¢ Validering f√∂r att undvika false positives"
echo "   ‚Ä¢ Multi-pass approach f√∂r 100% t√§ckning"
echo ""
echo "üöÄ K√∂r: python swedish_anonymizer_final_fixed.py"
